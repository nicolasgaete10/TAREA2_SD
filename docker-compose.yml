version: "3.8"

services:
  # --- 1. Dependencias Base (Persistencia) ---
  postgres:
    image: postgres:13
    container_name: postgres_db
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: yahoo_respuestas
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d yahoo_respuestas"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:6-alpine
    container_name: redis_cache
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- 2. Tarea 2: Bus de Mensajes (Kafka) ---
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10

  # --- 3. Tarea 2: Procesamiento de Flujos (Flink) ---
  flink-jobmanager:
    image: flink:1.14.3-scala_2.12-java11
    container_name: flink_jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    volumes:
      - flink_jobmanager_data:/opt/flink/data
    depends_on:
      kafka:
        condition: service_healthy

  flink-taskmanager:
    image: flink:1.14.3-scala_2.12-java11
    container_name: flink_taskmanager
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    depends_on:
      - flink-jobmanager

  flink-quality-checker:
    build: ./flink
    container_name: flink_job_submitter
    depends_on:
      flink-jobmanager:
        condition: service_started
    entrypoint: /bin/bash
    command: >
      -c "
        echo '--- Esperando 20s a que Flink JobManager esté listo... ---';
        sleep 20;
        echo '--- Enviando Job de PyFlink (flink.py) al Cluster... ---';
        /opt/flink/bin/flink run --python /opt/flink/usrlib/flink.py --jobmanager flink-jobmanager:8081
      "
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - FLINK_INPUT_TOPIC=resultados_procesados
      - FLINK_OUTPUT_VALIDATED_TOPIC=resultados_validados
      - FLINK_OUTPUT_RETRY_TOPIC=preguntas_pendientes
      - QUALITY_THRESHOLD=0.3
      - MAX_RETRIES=2
    restart: on-failure

  # --- 4. Servicios de Aplicación ---
  traffic_generator:
    build: ./traffic_generator
    container_name: traffic_generator
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_TOPIC=preguntas_pendientes
      - DATASET_PATH=/app/Data/test.csv
      - TRAFFIC_DISTRIBUTION=uniform
      - SIMULATION_TIME_MIN=10
    volumes:
      - ./Data:/app/Data
    depends_on:
      kafka:
        condition: service_healthy
    restart: on-failure

  procesador_llm:
    build: ./procesador_llm
    container_name: procesador_llm
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_INPUT_TOPIC=preguntas_pendientes
      - KAFKA_OUTPUT_TOPIC=resultados_procesados
      - REDIS_URL=redis://redis_cache:6379
      - KAFKA_RETRY_TOPIC_CUOTA=preguntas_reintento_cuota
      - KAFKA_DEAD_LETTER_TOPIC=preguntas_error_grave
    volumes:
      - ./Data:/app/Data
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: on-failure

  retry_worker:
    build: ./retry
    container_name: retry_worker
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_INPUT_TOPIC=preguntas_reintento_cuota
      - KAFKA_OUTPUT_TOPIC=preguntas_pendientes
      - RETRY_DELAY_SECONDS=60
    depends_on:
      kafka:
        condition: service_healthy
    restart: on-failure

  almacenamiento_kafka:
    build: ./almacenamiento_kafka
    container_name: almacenamiento_kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_INPUT_TOPIC=resultados_validados
      - STORAGE_SERVICE_URL=http://almacenamiento:5005/save
    depends_on:
      kafka:
        condition: service_healthy
      almacenamiento:
        condition: service_started
    restart: on-failure

  almacenamiento:
    build: ./almacenamiento
    container_name: almacenamiento
    environment:
      - DATABASE_URL=postgresql://user:password@postgres_db:5432/yahoo_respuestas
    ports:
      - "5005:5005"
    depends_on:
      postgres:
        condition: service_healthy
    restart: on-failure

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
    depends_on:
      - kafka

volumes:
  postgres_data:
  flink_jobmanager_data: